

RAG本身：

“你们为什么选择 RAG 方案？它解决了什么问题？有没有考虑过其他方案，比如直接对模型进行微调（Fine-tuning）？”
“你们的 RAG 流程是怎样的？文档是如何被切片（Chunking）和向量化的？用的是什么向量数据库？”


#### 关于前端的技术挑战（展现你的专业深度）：
##### “流式响应（Streaming）你是怎么实现的？”
回答思路：我们后端使用了 Server-Sent Events (SSE) / 或者基于 Fetch API 的 ReadableStream。前端接收到这种流式数据后，实时地将其追加到 UI 上，并实现打字机效果，这样用户几乎在请求发出的瞬间就能看到反馈，极大地优化了等待体验。
##### 长连接下的流式文本渲染 (Streaming Text Rendering)

1. 面临的问题与挑战 (The Problems)
“在AI项目中，用户最不能忍受的就是点击发送后，面对一个长久的加载菊花（spinner）。为了提供即时反馈，我们必须采用流式渲染。但这引入了几个核心挑战：”

- UI 阻塞与性能噩梦：如果后端以非常高的频率（比如每秒 50次）发来一个个 token（单词或字符），而我每次都用 setState 去更新整个文本块，会导致 React 组件以极高的频率进行 re-render。这会迅速阻塞浏览器的主线程，导致页面卡顿、用户输入无响应，体验极差。

- 不优雅的“打字机”效果：如何实现一个平滑、自然的打字机效果，而不是生硬的文本追加？如何处理 Markdown、代码块等富文本格式在流式输出时的正确渲染？

- 错误处理与中断：如果长连接在传输中途断开，UI应该如何响应？用户是否可以主动中断一个正在进行的、但看起来跑偏了的 AI 回复？

2. 解决方案 (The Solutions)

直接通过useRef直接操作dom，发完之后再统一setState。




##### “引用来源高亮是怎么做的？”
回答思路：后端在流式数据中会包含一些特殊标记来指明某段文本来自哪个文档的哪部分。前端需要解析这些标记，一方面将文本渲染出来，另一方面将来源信息储存起来。当用户悬停或点击文本时，我们能立刻找到并高亮对应的原始文档片段。

##### “在AI等待回复时，你是如何处理UI状态的？”
回答思路：我们设计了一套丰富的加载状态。比如会显示“正在搜索知识库...”、“正在生成答案...”等提示，让用户知道 AI 正在“思考”，而不是程序卡死了。同时，输入框会暂时禁用，防止用户重复提交。