

### 什么是RAG?

🛠️ RAG的核心流程

检索（Retrieval）：
从海量文档、数据库或互联网中快速查找与问题相关的信息（比如搜论文、找说明书）。

增强（Augmentation）：
把检索到的内容“喂”给AI模型，让它结合这些资料理解问题。

生成（Generation）：
基于检索到的信息和自身知识库，生成最终答案（并标注来源）。


#### 检索召回？
检索召回（Retrieval）是 RAG（Retrieval-Augmented Generation）系统中的关键步骤，指的是从大量文档中找出与用户查询相关的文档片段的过程。

##### 经典流程：
- 问题预处理
- 文档检索
- 召回
- 构建提示词
- 生成答案

##### 子问题拆分？
对于“A 和 B 的对比”、“介绍 X 并说明其优缺点”这类复杂问题，直接进行 RAG 的效果不佳。我们设计了一套子问题拆分机制来应对：

主要实现方式: 我们利用了 LLM 本身的能力。通过设计一个专门的 “元提示词” (Meta-Prompt) 来引导一个 LLM (可以是另一个更小、更快的模型) 充当“问题分解器”。

具体流程:
当系统识别到复杂问题时（可以通过关键词、问题长度或另一个分类模型判断），会先调用“问题分解器”LLM。
我们会给它这样的指令：“请将以下复杂问题分解成 N 个独立的、可以被单独回答的子问题：[用户的原始问题]”。

LLM 会返回一个子问题列表，例如 ["什么是 A？", "什么是 B？", "A 和 B 有哪些共同点？", "A 和 B 有哪些不同点？"]。

系统会并行地为每一个子问题执行一遍完整的 RAG 流程，得到每个子问题的答案。
最后，将所有子答案和原始问题再次提交给 LLM，并指示它：“请根据以下信息，综合成一个流畅、连贯的最终答案”，从而生成最终的完整回答。

这个机制将一个复杂任务转化为了多个简单的、可独立处理的任务，大大提升了对复杂问题的处理能力和答案的结构性。

##### 面试官延伸追问:
向量数据库选型时你们主要考虑了哪些因素？为什么选择你当前使用的这款？

如何量化评估你的 RAG 系统优化（如混合检索）是有效的？你们用了哪些评估指标？

文档切片（Chunking）的大小和重叠（Overlap）是如何权衡和决定的？这两种参数分别会带来什么影响？

如果检索出的上下文存在相互矛盾或错误的信息，LLM 会如何表现？你有什么方法可以缓解这个问题？